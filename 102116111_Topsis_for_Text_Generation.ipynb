{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7c175b7e-beed-4bff-b7db-e641698cb080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "41b53672-e888-41db-b10e-5bc4a16813b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "df36fa47-be6d-44f9-9300-920575abcb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jatin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d0276-5c9b-4ecd-baf4-8546a95255e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d620e61-d0e8-417d-b714-5ec2937b0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f607d1-f23f-4e6f-9ed7-67199b49db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f86877-1183-48bd-8397-e45fd083232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc4914-0333-45c0-867f-e6f7c1d18a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da01358-2abf-4a94-bbeb-927d917d6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a720e8-f867-46fd-9c62-c36e6e2652d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce555d-6941-4f53-af67-95768fcb4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"microsoft/DialoGPT-medium\",\n",
    "    \"Pi3141/DialoGPT-medium-elon-2\",\n",
    "    \"0xDEADBEA7/DialoGPT-small-rick\",\n",
    "    \"satvikag/chatbot\",\n",
    "    \"microsoft/DialoGPT-large\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98b832-272a-472b-a42a-ca49a506903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Describe your dream vacation destination.\",\n",
    "    \"Share a hobby or activity you enjoy in your free time.\",\n",
    "    \"What's your favorite type of cuisine, and why?\",\n",
    "    \"If you could learn any new skill, what would it be?\",\n",
    "    \"Tell me about a memorable achievement or accomplishment in your life.\"\n",
    "]\n",
    "\n",
    "responses = [\n",
    "    \"My dream vacation destination is a tropical island with pristine beaches and crystal-clear waters.\",\n",
    "    \"In my free time, I enjoy painting landscapes and exploring my artistic side.\",\n",
    "    \"I love Italian cuisine because of its delicious pasta dishes and flavorful sauces.\",\n",
    "    \"If I could learn a new skill, I would choose to play a musical instrument, like the piano.\",\n",
    "    \"One of my most memorable achievements was completing a marathon and achieving a personal best.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900d478-d49f-47dc-8e2d-66ec8c34400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d3f09-5e21-45ad-ab22-8e9278d8e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(references, candidates):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return corpus_bleu(references, candidates, smoothing_function=smoothie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4166d4a-ff2d-4bfc-a6c9-afe97e27981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "\n",
    "def calculate_bleu(references, candidates):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    references_tokenized = [tuple(ref.split()) for sublist in references for ref in sublist]\n",
    "    candidates_tokenized = [tuple(cand.split()) for sublist in candidates for cand in sublist]\n",
    "    return corpus_bleu([references_tokenized], [candidates_tokenized], smoothing_function=smoothie)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a989a01-37d8-4ec0-983b-c58ebeb1412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge(references, candidate):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(references, candidate)\n",
    "    rouge1 = scores['rouge1'].fmeasure\n",
    "    rouge2 = scores['rouge2'].fmeasure\n",
    "    rougeL = scores['rougeL'].fmeasure\n",
    "    return rouge1, rouge2, rougeL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5d6ed-6227-4120-853e-edf304798cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models:\n",
    "    bleu_scores = []\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "    response_lengths = []\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    input_ids = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids=input_ids, max_length=100)\n",
    "\n",
    "    generated_responses = [tokenizer.decode(ids, skip_special_tokens=True) for ids in output]\n",
    "\n",
    "    for response, generated_response in zip(responses, generated_responses):\n",
    "        # Calculate BLEU score\n",
    "        bleu_score = calculate_bleu([[response]], [[generated_response]])\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "        # Calculate ROUGE scores\n",
    "        rouge1, rouge2, rougeL = calculate_rouge(response, generated_response)\n",
    "        rouge1_scores.append(rouge1)\n",
    "        rouge2_scores.append(rouge2)\n",
    "        rougeL_scores.append(rougeL)\n",
    "\n",
    "        # Calculate response length\n",
    "        response_lengths.append(len(generated_response.split()))\n",
    "\n",
    "    # Calculate average scores\n",
    "    avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "    avg_rouge1_score = sum(rouge1_scores) / len(rouge1_scores)\n",
    "    avg_rouge2_score = sum(rouge2_scores) / len(rouge2_scores)\n",
    "    avg_rougeL_score = sum(rougeL_scores) / len(rougeL_scores)\n",
    "    avg_response_length = sum(response_lengths) / len(response_lengths)\n",
    "\n",
    "    # Store results\n",
    "    results_dict[model_name] = {\n",
    "        \"BLEU\": avg_bleu_score,\n",
    "        \"ROUGE-1\": avg_rouge1_score,\n",
    "        \"ROUGE-2\": avg_rouge2_score,\n",
    "        \"ROUGE-L\": avg_rougeL_score,\n",
    "        \"Response Length\": avg_response_length\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf45d35-6166-463c-8db1-2759691c41e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde261a-21af-4b1c-abe6-1945332cac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('results.csv')\n",
    "data = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078eec65-6897-4010-acb8-b0b8e124d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data=pd.read_csv(\"results.csv\")\n",
    "weights = '1,1,1,1,1'\n",
    "impacts = '+,+,+,+,-'\n",
    "import sys\n",
    "# HANDLING EXCEPTIONS\n",
    "if data.shape[1] < 3:\n",
    "    raise ValueError(\"Input file does not contain three or more columns.\")\n",
    "if not data.iloc[:, 1:].apply(np.isreal).all().all():\n",
    "    raise ValueError(\"Columns from 2nd to last do not contain numeric values only.\")\n",
    "if len(weights.split(',')) != len(impacts.split(',')) != data.shape[1] - 1:\n",
    "    raise ValueError(\"Number of weights, impacts, and columns must be the same.\")\n",
    "if not all(impact in ['+', '-'] for impact in impacts.split(',')):\n",
    "    raise ValueError(\"Impacts must be either +ve or -ve.\")\n",
    "    \n",
    "# TOPSIS PROGRAM\n",
    "def vector_normalization(data):\n",
    "    normalized_data = data.iloc[:, 1:].apply(\n",
    "        lambda x: x / np.sqrt(np.sum(x**2)), axis=0)\n",
    "    return normalized_data\n",
    "\n",
    "normalized_data = vector_normalization(data)\n",
    "weighted_normalized_matrix = normalized_data * list(map(float, weights.split(',')))\n",
    "ideal_best = weighted_normalized_matrix.max(\n",
    ") if impacts[0] == '+' else weighted_normalized_matrix.min()\n",
    "ideal_worst = weighted_normalized_matrix.min(\n",
    ") if impacts[0] == '+' else weighted_normalized_matrix.max()\n",
    "performance_score = np.sqrt(np.sum((weighted_normalized_matrix - ideal_worst)**2, axis=1)) / (\n",
    "    np.sqrt(np.sum((weighted_normalized_matrix - ideal_best)**2, axis=1)) +\n",
    "    np.sqrt(np.sum((weighted_normalized_matrix - ideal_worst)**2, axis=1))\n",
    ")\n",
    "\n",
    "result_topsis = data.copy()\n",
    "result_topsis['Topsis Score'] =  performance_score\n",
    "result_topsis['Rank'] = result_topsis['Topsis Score'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc87573-49c6-4b24-8f4a-52dc5ea5b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(topsis_results_sorted.index, topsis_results_sorted['Topsis Score'], color='green')\n",
    "plt.xlabel('TOPSIS Score')\n",
    "plt.ylabel('Model')\n",
    "plt.title('TOPSIS Ranking of Models')\n",
    "plt.gca().invert_yaxis() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d4cec-b6fd-45a0-ad95-2374474b959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topsis_columns = ['Unnamed: 0', 'BLEU', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'Response Length', 'Topsis Score', 'Rank']\n",
    "\n",
    "# Create a new DataFrame with the selected columns for TOPSIS results\n",
    "topsis_csv_data = topsis_results[topsis_columns]\n",
    "\n",
    "# Save the new TOPSIS results to a CSV file\n",
    "topsis_csv_data.to_csv('topsis_results.csv', index=False)\n",
    "\n",
    "print(\"TOPSIS results saved to topsis_results.csv\")\n",
    "\n",
    "# Plotting TOPSIS Bar Graph\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(result_topsis['Unnamed: 0'], result_topsis['Topsis Score'], color='purple')\n",
    "plt.xlabel('TOPSIS Score')\n",
    "plt.ylabel('Model')\n",
    "plt.title('TOPSIS Ranking of Models')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.tight_layout()\n",
    "plt.savefig('topsis_BarGraph.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"TOPSIS Bar Graph saved to topsis_BarGraph.png\")\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = calculate_bleu([response], [generated_response])\n",
    "\n",
    "# Plotting function for each metric\n",
    "metrics = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L','BLEU']\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(data.index, data[metric], color='purple')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{metric}_comparison.png')\n",
    "    plt.show()\n",
    "\n",
    "# Plotting response length\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(data.index, data['Response Length'], color='purple')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Response Length')\n",
    "plt.title('Response Length Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('response_length_comparison.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
